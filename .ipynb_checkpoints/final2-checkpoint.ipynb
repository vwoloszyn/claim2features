{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim2Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ml_utils import myHotEncode, myHotDecode, plot_confusion_matrix, text_to_wordEmbedding\n",
    "from utils.text_utils import treat_text, pure_words, words_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "data_path = 'dataset.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "columns = ['tag', 'text', 'attrs', 'level', 'brother_tag', 'brother_text', 'brother_attrs', 'url', 'site', 'label']\n",
    "words_context = []\n",
    "brother_words_context = []\n",
    "\n",
    "for tupla in df[columns].values:\n",
    "    # In order to facilitate each instance is a dictionary 'dic'\n",
    "    dic = {}\n",
    "    for i, column in enumerate(columns):\n",
    "        if column == 'text' or column == 'brother_text':\n",
    "            dic[column] = str(tupla[i])\n",
    "        else:\n",
    "            dic[column] = tupla[i]\n",
    "    \n",
    "    # words_context attribute: the attrs is replace for words_context\n",
    "    words_context_ = ''\n",
    "    attrs = ast.literal_eval(dic['attrs'])\n",
    "    for attr in attrs.values():\n",
    "        if type(attr) == str:\n",
    "            words_context_ += pure_words(treat_text(str(attr))) + ' '\n",
    "        else:\n",
    "            for a in attr:\n",
    "                words_context_ += pure_words(treat_text(str(a))) + ' '\n",
    "    words_context.append(words_context_)\n",
    "    \n",
    "    # brother_words_context attribute: : the brother_attrs is replace for brother_words_context\n",
    "    brother_words_context_ = ''\n",
    "    attrs = ast.literal_eval(dic['brother_attrs'])\n",
    "    for attr in attrs.values():\n",
    "        if type(attr) == str:\n",
    "            brother_words_context_ += pure_words(treat_text(str(attr))) + ' '\n",
    "        else:\n",
    "            for a in attr:\n",
    "                brother_words_context_ += pure_words(treat_text(str(a))) + ' '\n",
    "    brother_words_context.append(brother_words_context_)\n",
    "    \n",
    "\n",
    "del df['attrs']\n",
    "df['words_context'] = words_context\n",
    "\n",
    "del df['brother_attrs']\n",
    "df['brother_words_context'] = brother_words_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words for context words in attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "\n",
    "vocab_size = 2000\n",
    "vec = CountVectorizer(max_features=vocab_size, stop_words=ENGLISH_STOP_WORDS, tokenizer=LemmaTokenizer())\n",
    "vec.fit(df['words_context'])\n",
    "words_context = vec.transform(list(df['words_context'])).toarray()\n",
    "brother_words_context = vec.transform(list(df['brother_words_context'])).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec for text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v_patch = 'C:\\word_embedding\\GoogleNews-vectors-negative300.bin'\n",
    "w2v = KeyedVectors.load_word2vec_format(w2v_patch, unicode_errors=\"ignore\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2vec text feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['text_w2v'] = text_to_wordEmbedding(list(df['text']), w2v)\n",
    "df['brother_text_w2v'] = text_to_wordEmbedding(list(df['brother_text']), w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sizes = []\n",
    "for size in df['text']:\n",
    "    if type(size) == str:\n",
    "        text_sizes.append([words_count(size)])\n",
    "    else:\n",
    "        text_sizes.append([0])\n",
    "brother_text_sizes = []\n",
    "for size in df['brother_text']:\n",
    "    if type(size) == str:\n",
    "        brother_text_sizes.append([words_count(size)])\n",
    "    else:\n",
    "        brother_text_sizes.append([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2Idx = myHotEncode([df['tag']], 100)[1]\n",
    "tag = myHotEncode([[x] for x in df['tag']], vocab2idx=tag2Idx)[0]\n",
    "brother_tag = myHotEncode([[x] for x in df['brother_tag']], vocab2idx=tag2Idx)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = df['level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "last_levels = [-1]\n",
    "last_labels = ['None']\n",
    "\n",
    "last_tags = []\n",
    "last_text_sizes = []\n",
    "last_words_contexts = []\n",
    "last_wordEmbedding = []\n",
    "last_brother_tags = []\n",
    "last_brother_text_sizes = []\n",
    "last_brother_words_contexts = []\n",
    "last_brother_wordEmbedding = []\n",
    "\n",
    "\n",
    "def features(tag, text_size, words_context, wordEmbedding, level,\n",
    "             brother_tag, brother_text_size, brother_words_context, brother_wordEmbedding,\n",
    "             parent_tag, parent_text_size, parent_words_context, parent_wordEmbedding):\n",
    "    # Tag\n",
    "    #return list(tag)\n",
    "    \n",
    "    # Level\n",
    "    #return [level]\n",
    "    \n",
    "    # Words Contexts\n",
    "    #return list(words_context)\n",
    "    \n",
    "    # Words Embedding\n",
    "    return list(wordEmbedding)\n",
    "    \n",
    "    # Text sizes\n",
    "    #return list(text_size)\n",
    "\n",
    "    # Brothers tags\n",
    "    #return list(brother_tag)\n",
    "    \n",
    "    # Brothers text sizes\n",
    "    #return list(brother_text_size)\n",
    "    \n",
    "    # Brothers words contexts\n",
    "    #return list(brother_words_context)\n",
    "    \n",
    "    # Parent tag\n",
    "    #return list(parent_tag)\n",
    "    \n",
    "    # Parent text size\n",
    "    #return list(parent_text_size)\n",
    "    \n",
    "    # Parent words contexts\n",
    "    #return list(parent_words_context)\n",
    "    \n",
    "    # All\n",
    "    #return list(tag) + list(text_size) + list(words_context) + [level] + list(brother_tag) + list(brother_text_size) + list(brother_words_context) + list(parent_tag) + list(parent_text_size) + list(parent_words_context)\n",
    "    \n",
    "\n",
    "\n",
    "X = []\n",
    "X_ = []\n",
    "y = []\n",
    "group = []\n",
    "last_group = None\n",
    "last_url = 'NONE'\n",
    "\n",
    "sizes = set()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if last_url != 'NONE' and df['url'][i] != last_url:\n",
    "        if len(last_tags) > 0:\n",
    "            # Parent\n",
    "            if len(last_tags) > 1:\n",
    "                parent_tag = last_tags[-2]\n",
    "                parent_text_size = last_text_sizes[-2]\n",
    "                parent_words_context = last_words_contexts[-2]\n",
    "            else:\n",
    "                print(\"here???\")\n",
    "                parent_tag = np.zeros(len(last_tags[-1]))\n",
    "                parent_text_size = np.zeros(len(last_text_sizes[-1]))\n",
    "                parent_words_contexts = np.zeros(len(last_words_contexts[-1]))\n",
    "            x = features(last_tags[-1], last_text_sizes[-1], last_words_contexts[-1], last_levels[-1], \n",
    "                         last_brother_tags[-1], last_brother_text_sizes[-1], last_brother_words_contexts[-1],\n",
    "                         parent_tag, parent_text_size, parent_words_context)\n",
    "            X.append(x)\n",
    "            X_.append(list(last_tags[-1]).index(1)) # Debug control\n",
    "            sizes.add(len(x))\n",
    "            y_ = 'None'\n",
    "            for y__ in last_labels:\n",
    "                if y__ != 'None':\n",
    "                    y_ = y__\n",
    "            y.append(y_)\n",
    "            group.append(last_group)\n",
    "            last_labels = ['None']\n",
    "            last_tags = []\n",
    "            last_text_sizes = []\n",
    "            last_words_contexts = []\n",
    "            last_levels = [-1]\n",
    "            last_brother_tags = []\n",
    "            last_brother_text_sizes = []\n",
    "            last_brother_words_contexts = []\n",
    "        last_url = df['url'][i]\n",
    "        continue\n",
    "        \n",
    "    last_url = df['url'][i]\n",
    "    level_ = df['level'][i]\n",
    "    \n",
    "    if level_ > last_levels[-1]:\n",
    "        last_tags.append(tag[i])\n",
    "        last_text_sizes.append(text_sizes[i])\n",
    "        last_words_contexts.append(words_context[i])\n",
    "        last_levels.append(level_)\n",
    "        last_brother_tags.append(brother_tag[i])\n",
    "        last_brother_text_sizes.append(brother_text_sizes[i])\n",
    "        last_brother_words_contexts.append(brother_words_context[i])\n",
    "        last_labels.append(df['label'][i])\n",
    "            \n",
    "    else:\n",
    "        if len(last_tags) > 0:\n",
    "            # Parent\n",
    "            if len(last_tags) > 1:\n",
    "                parent_tag = last_tags[-2]\n",
    "                parent_text_size = last_text_sizes[-2]\n",
    "                parent_words_context = last_words_contexts[-2]\n",
    "            else:\n",
    "                print(\"here???\")\n",
    "                parent_tag = np.zeros(len(last_tags[-1]))\n",
    "                parent_text_size = np.zeros(len(last_text_sizes[-1]))\n",
    "                parent_words_contexts = np.zeros(len(last_words_contexts[-1]))\n",
    "            x = features(last_tags[-1], last_text_sizes[-1], last_words_contexts[-1], last_levels[-1], \n",
    "                         last_brother_tags[-1], last_brother_text_sizes[-1], last_brother_words_contexts[-1],\n",
    "                         parent_tag, parent_text_size, parent_words_context)\n",
    "            X.append(x)\n",
    "            X_.append(list(last_tags[-1]).index(1))  # Debug control\n",
    "            sizes.add(len(x))\n",
    "            y_ = 'None'\n",
    "            for y__ in last_labels:\n",
    "                if y__ != 'None':\n",
    "                    y_ = y__\n",
    "            y.append(y_)\n",
    "            group.append(last_group)\n",
    "            # Remove last data used\n",
    "            last_labels = last_labels[:level_-1]\n",
    "            last_tags = last_tags[:level_-1]\n",
    "            last_text_sizes = last_text_sizes[:level_-1]\n",
    "            last_words_contexts = last_words_contexts[:level_-1]\n",
    "            last_levels = last_levels[:level_-1]\n",
    "            last_brother_tags = last_brother_tags[:level_-1]\n",
    "            last_brother_text_sizes = last_brother_text_sizes[:level_-1]\n",
    "            last_brother_words_contexts = last_brother_words_contexts[:level_-1]\n",
    "\n",
    "            last_tags.append(tag[i])\n",
    "            last_text_sizes.append(text_sizes[i])\n",
    "            last_words_contexts.append(words_context[i])\n",
    "            last_levels.append(level_)\n",
    "            last_brother_tags.append(brother_tag[i])\n",
    "            last_brother_text_sizes.append(brother_text_sizes[i])\n",
    "            last_brother_words_contexts.append(brother_words_context[i])\n",
    "            last_labels.append(df['label'][i])\n",
    "    last_group = df['site'][i]\n",
    "\n",
    "if len(last_tags) > 0:\n",
    "    # Parent\n",
    "    if len(last_tags) > 1:\n",
    "        parent_tag = last_tags[-2]\n",
    "        parent_text_size = last_text_sizes[-2]\n",
    "        parent_words_context = last_words_contexts[-2]\n",
    "    else:\n",
    "        print(\"here???\")\n",
    "        parent_tag = np.zeros(len(last_tags[-1]))\n",
    "        parent_text_size = np.zeros(len(last_text_sizes[-1]))\n",
    "        parent_words_contexts = np.zeros(len(last_words_contexts[-1]))\n",
    "    x = features(last_tags[-1], last_text_sizes[-1], last_words_contexts[-1], last_levels[-1], \n",
    "                 last_brother_tags[-1], last_brother_text_sizes[-1], last_brother_words_contexts[-1],\n",
    "                 parent_tag, parent_text_size, parent_words_context)\n",
    "    X.append(x)\n",
    "    X_.append(list(last_tags[-1]).index(1)) # Debug control\n",
    "    sizes.add(len(x))\n",
    "    y_ = 'None'\n",
    "    for y__ in last_labels:\n",
    "        if y__ != 'None':\n",
    "            y_ = y__\n",
    "    y.append(y_)\n",
    "    group.append(last_group)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "group = np.array(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "confusion = []\n",
    "\n",
    "# Aux print\n",
    "_, site2Idx = myHotEncode([[u] for u in group])\n",
    "\n",
    "gp = GroupKFold(n_splits=11)\n",
    "for train_indexs, test_indexs in gp.split(X, groups=group):\n",
    "    \n",
    "    X_train = X[train_indexs]\n",
    "    y_train = y[train_indexs]\n",
    "    \n",
    "    X_test = X[test_indexs]\n",
    "    y_test = y[test_indexs]\n",
    "    \n",
    "    groups_train = group[train_indexs]\n",
    "    groups_test = group[test_indexs]\n",
    "    train_g = set()\n",
    "    test_g = set()\n",
    "    for g in groups_train:\n",
    "        train_g.add(site2Idx[g])\n",
    "    for g in groups_test:\n",
    "        test_g.add(site2Idx[g])\n",
    "    print('Train Groups (URLs)', train_g)\n",
    "    print('Test Groups (URLs)', test_g)\n",
    "    \n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    result = svm.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(result, y_test)\n",
    "    accuracy.append(acc)\n",
    "    p = precision_score(result, y_test, average=\"macro\")\n",
    "    precision.append(p)\n",
    "    r = recall_score(result, y_test, average=\"macro\")\n",
    "    recall.append(r)\n",
    "    f = f1_score(result, y_test, average=\"macro\")\n",
    "    f1.append(f)\n",
    "    cm_ = confusion_matrix(result, y_test)\n",
    "    plot_confusion_matrix(cm_, svm.classes_, normalize=True) \n",
    "    confusion.append(cm_)\n",
    "    \n",
    "    print(\"%s: %.2f %%\" % ('Acc', acc*100))\n",
    "    print(\"%s: %.2f %%\" % ('Precision', p*100))\n",
    "    print(\"%s: %.2f %%\" % ('Recall', r*100))\n",
    "    print(\"%s: %.2f %%\" % ('F1', f*100))\n",
    "    print('')\n",
    "\n",
    "print(\"Acc %.2f %% (+/- %.2f %%)\" % (np.mean(accuracy)*100, np.std(accuracy)*100))\n",
    "print(\"Precision %.2f %% (+/- %.2f %%)\" % (np.mean(precision)*100, np.std(precision)*100))\n",
    "print(\"Recall %.2f %% (+/- %.2f %%)\" % (np.mean(recall)*100, np.std(recall)*100))\n",
    "print(\"F1 %.2f %% (+/- %.2f %%)\" % (np.mean(f1)*100, np.std(f1)*100))\n",
    "\n",
    "nc = []\n",
    "for c in confusion:\n",
    "    d = len(svm.classes_) - len(c)\n",
    "    c = np.pad(c, (0,d), 'constant')\n",
    "    nc.append(c)\n",
    "confusion = nc\n",
    "cm = np.mean(confusion, axis=0)\n",
    "plot_confusion_matrix(cm, svm.classes_, normalize=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug and Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_, y_, g_ in zip(X,y,group):\n",
    "    if y_ == 'Credibility' and g_ != 'checkyourfact':\n",
    "        print(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.predict([[x__] for x__ in range(0,350)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site2Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "confusion = []\n",
    "\n",
    "X_train = X[:20000]\n",
    "y_train = y[:20000]\n",
    "    \n",
    "X_test = X[20000:]\n",
    "y_test = y[20000:]\n",
    "\n",
    "svm = RandomForestClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "result = svm.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(result, y_test)\n",
    "accuracy.append(acc)\n",
    "p = precision_score(result, y_test, average=\"macro\")\n",
    "precision.append(p)\n",
    "r = recall_score(result, y_test, average=\"macro\")\n",
    "recall.append(r)\n",
    "f = f1_score(result, y_test, average=\"macro\")\n",
    "f1.append(f)\n",
    "confusion.append(confusion_matrix(result, y_test))\n",
    "    \n",
    "print(\"%s: %.2f %%\" % ('Acc', acc*100))\n",
    "print(\"%s: %.2f %%\" % ('Precision', p*100))\n",
    "print(\"%s: %.2f %%\" % ('Recall', r*100))\n",
    "print(\"%s: %.2f %%\" % ('F1', f*100))\n",
    "print('')\n",
    "\n",
    "print(\"Acc %.2f %% (+/- %.2f %%)\" % (np.mean(accuracy)*100, np.std(accuracy)*100))\n",
    "print(\"Precision %.2f %% (+/- %.2f %%)\" % (np.mean(precision)*100, np.std(precision)*100))\n",
    "print(\"Recall %.2f %% (+/- %.2f %%)\" % (np.mean(recall)*100, np.std(recall)*100))\n",
    "print(\"F1 %.2f %% (+/- %.2f %%)\" % (np.mean(f1)*100, np.std(f1)*100))\n",
    "\n",
    "nc = []\n",
    "for c in confusion:\n",
    "    d = len(svm.classes_) - len(c)\n",
    "    c = np.pad(c, (0,d), 'constant')\n",
    "    nc.append(c)\n",
    "confusion = nc\n",
    "cm = np.mean(confusion, axis=0)\n",
    "plot_confusion_matrix(cm, svm.classes_, normalize=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
