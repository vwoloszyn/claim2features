{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot encode and decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def myHotEncode(input_data, max_vocab=0, vocab2idx=None):\n",
    "    \"Return the hot-vecotor and the vocab2idx.\"\n",
    "    if vocab2idx is None:\n",
    "        vocabFreq = {}\n",
    "        for i in input_data:\n",
    "            for j in i:\n",
    "                if j not in vocabFreq:\n",
    "                    vocabFreq[j] = 0\n",
    "                vocabFreq[j] += 1\n",
    "        vocabFreq = OrderedDict(sorted(vocabFreq.items(), key=itemgetter(1), reverse=True))\n",
    "        vocab2idx = {}\n",
    "        count = 0\n",
    "        for v in vocabFreq:\n",
    "            count += 1\n",
    "            if max_vocab > 0 and count > max_vocab:\n",
    "                break\n",
    "            vocab2idx[v] = len(vocab2idx)        \n",
    "    vocabEmbeddings = np.identity(len(vocab2idx), dtype='float32')\n",
    "    data_ret = []\n",
    "    for i in input_data:\n",
    "        i_ = []\n",
    "        for j in i:\n",
    "            if j in vocab2idx:\n",
    "                i_.append(vocabEmbeddings[vocab2idx[j]])\n",
    "        data_ret.append(sum(i_))\n",
    "    if len(data_ret) == 0:\n",
    "        data_ret = np.zeros(len(vocab2idx))\n",
    "    return data_ret, vocab2idx\n",
    "\n",
    "\n",
    "def myHotDecode(input_data, vocab2idx):\n",
    "    \"Return the decode as final representation and decode as indexs\"\n",
    "    data_ = []\n",
    "    data_idx = []\n",
    "    for i in input_data:\n",
    "        i_ = []\n",
    "        i_idx = []\n",
    "        if len(i) != len(vocab2idx):\n",
    "            print('Erro:', 'The vocab2idx not fit the input data!')\n",
    "            return\n",
    "        for _i, j in enumerate(i):\n",
    "            if j > 0:\n",
    "                v = [k for k in vocab2idx if vocab2idx[k]==_i][0]\n",
    "                i_.append(v)\n",
    "                i_idx.append(_i)\n",
    "        data_.append(i_)\n",
    "        data_idx.append(i_idx)\n",
    "    return data_, data_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treat a list of str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def treat_str_list(input_list):\n",
    "    ret = []\n",
    "    for s in input_list:\n",
    "        ret += [ss.lower().strip() for ss in re.split('[\\W_]+', s)]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_path = 'features_annotated.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "columns = ['attrs', 'label', 'level', 'tag', 'text', 'url']\n",
    "\n",
    "last_url = ''\n",
    "batches = []\n",
    "\n",
    "css_tss = []\n",
    "id_tss = []\n",
    "level_tss = []\n",
    "tag_tss = []\n",
    "css_ts = []\n",
    "id_ts = []\n",
    "level_ts = []\n",
    "tag_ts = []\n",
    "\n",
    "labels = []\n",
    "labels_batch = []\n",
    "label = 'None'\n",
    "\n",
    "last_level = -1\n",
    "\n",
    "for attr, label_, level, tag, text, url in df[columns].values:\n",
    "    attr = ast.literal_eval(attr)\n",
    "    if url != last_url:\n",
    "        css_tss.append(css_ts.copy())\n",
    "        id_tss.append(id_ts.copy())\n",
    "        level_tss.append(level_ts.copy())\n",
    "        tag_tss.append(tag_ts.copy())\n",
    "        css_ts = []\n",
    "        id_ts = []\n",
    "        level_ts = []\n",
    "        tag_ts = []\n",
    "        labels_batch.append(label)\n",
    "        aux_list = []\n",
    "        aux_list.append(css_tss.copy())\n",
    "        aux_list.append(id_tss.copy())\n",
    "        aux_list.append(level_tss.copy())\n",
    "        aux_list.append(tag_tss.copy())\n",
    "        batches.append(aux_list)\n",
    "        css_tss = []\n",
    "        id_tss = []\n",
    "        level_tss = []\n",
    "        tag_tss = []\n",
    "        labels.append(labels_batch.copy())\n",
    "        labels_batch = []\n",
    "        last_url = url\n",
    "        label = 'None'\n",
    "    if label_ != 'None':\n",
    "        label = label_\n",
    "    if not level > last_level:\n",
    "        css_tss.append(css_ts.copy())\n",
    "        id_tss.append(id_ts.copy())\n",
    "        level_tss.append(level_ts.copy())\n",
    "        tag_tss.append(tag_ts.copy())\n",
    "        css_ts = css_ts[:level]\n",
    "        id_ts = id_ts[:level]\n",
    "        level_ts = level_ts[:level]\n",
    "        tag_ts = tag_ts[:level]\n",
    "        labels_batch.append(label)\n",
    "    \n",
    "    # Features\n",
    "    if 'class' in attr:\n",
    "        css_ts.append(treat_str_list(attr['class']))\n",
    "        #css_ts += treat_str_list(attr['class'])\n",
    "    else:\n",
    "        css_ts.append([])\n",
    "    aux_list = []\n",
    "    if 'id' in attr:\n",
    "        #aux_list.append(treat_str_list([attr['id']]))\n",
    "        aux_list += treat_str_list([attr['id']])\n",
    "    if 'name' in attr:\n",
    "        #aux_list.append(treat_str_list([attr['name']]))\n",
    "        aux_list += treat_str_list([attr['name']])\n",
    "        \n",
    "    id_ts.append(aux_list)\n",
    "    tag_ts.append([tag])\n",
    "    level_ts.append([level])\n",
    "    last_level = level\n",
    "\n",
    "css_tss.append(css_ts.copy())\n",
    "id_tss.append(id_ts.copy())\n",
    "level_tss.append(level_ts.copy())\n",
    "tag_tss.append(tag_ts.copy())\n",
    "labels_batch.append(label)\n",
    "aux_list = []\n",
    "aux_list.append(css_tss.copy())\n",
    "aux_list.append(id_tss.copy())\n",
    "aux_list.append(level_tss.copy())\n",
    "aux_list.append(tag_tss.copy())\n",
    "batches.append(aux_list)\n",
    "labels.append(labels_batch.copy())\n",
    "batches = batches[1:]\n",
    "labels = labels[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "css_ = []\n",
    "id_ = []\n",
    "tag_ = []\n",
    "for batch in batches:\n",
    "    for css in batch[0]:\n",
    "        for i in css:\n",
    "            css_.append(i)\n",
    "    for _id in batch[1]:\n",
    "        for i in _id:\n",
    "            id_.append(i)\n",
    "    for tag in batch[3]:\n",
    "        for i in tag:\n",
    "            tag_.append(i)\n",
    "_, css2Idx = myHotEncode(css_, 100)\n",
    "_, id2Idx = myHotEncode(id_, 100)\n",
    "_, tag2Idx = myHotEncode(tag_, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i0, batch in enumerate(batches):\n",
    "    # CSS classes\n",
    "    for i1, sample in enumerate(batch[0]):\n",
    "        for i2, timestep in enumerate(sample):\n",
    "            timestep_, _ = myHotEncode(timestep, vocab2idx=css2Idx)\n",
    "            batches[i0][0][i1][i2] = timestep_\n",
    "    # ID and Names\n",
    "    for i1, sample in enumerate(batch[1]):\n",
    "        for i2, timestep in enumerate(sample):\n",
    "            timestep_, _ = myHotEncode(timestep, vocab2idx=id2Idx)\n",
    "            batches[i0][1][i1][i2] = timestep_\n",
    "    # Tags\n",
    "    for i1, sample in enumerate(batch[3]):\n",
    "        for i2, timestep in enumerate(sample):\n",
    "            timestep_, _ = myHotEncode(timestep, vocab2idx=tag2Idx)\n",
    "            batches[i0][3][i1][i2] = timestep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], []]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
